[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/pca-curva-juros/pca-curva-juros.html",
    "href": "posts/pca-curva-juros/pca-curva-juros.html",
    "title": "Curva de juros: um conto de três fatores",
    "section": "",
    "text": "1 Preparo e exploração dos dados\n\nrm(list=ls())\nlibrary(tidyverse)\nlibrary(rb3) # Dados da B3 \nlibrary(fixedincome) # Manipulação de dados de renda fixa e juros\nlibrary(bizdays) # Calendários\nlibrary(plotly)\n\nlibrary(xts)\n\n# options(download.file.method=\"wininet\")\n# devtools::install_github('thomasp85/gganimate')\nlibrary(gganimate)\nlibrary(reactable)\n\npaleta_cores = c('#b8acd1', '#e2d5f1', '#c9e8fd', '#526d85', '#4e4466',\n                 '#eccfb0', '#e06666', '#6fa8dc', '#0b5394', '#351c75',\n                '#4b2328', '#a86800', '#395a57', '#9ab7c4', '#5e627b')\n\nadd_title &lt;- function(x,title_str, subtitle_str = ''){\n  x |&gt;\n  plotly::layout(title = list(text = paste0('&lt;b&gt;',title_str, '&lt;/b&gt;','&lt;br&gt;','&lt;sup&gt;',subtitle_str,'&lt;/sup&gt;')))\n  }\n\nA ideia do notebook é a partir do dos contratos futuros de DI construir a estrutura a termo de juros da economia brasileira. Por fim, vamos aplicar uma Análise de Componentes Principais e encontrar os fatores de risco latentes na curva de juros. Se você já ouviu falar em Nelson-Siegel, você já deve imaginar quais são.\nNa análise, serão usados os ajustes dos contratos negociados na B3 — e tem bastante coisa, de boi-gordo a câmbio, de cupom cambial a café. Os dados podem ser obtidos facilmente por meio do pacote rb3. Vou utilizar também o pacote fixedincome. Ambos foram desenvolvidos pelo Wilson Freitas e facilitam bastante a vida.\n\n# Baixandos os dados da B3 (leva um tempinho, lembre-se de manter o cache para não deixar o TI da bolsa maluco)\n# ajustesB3 &lt;- futures_mget(first_date = '2006-01-01', last_date =  Sys.Date(), \n#                   do_cache = T)\n# saveRDS(ajustesB3,'data/b3_ajustes.rds')\n\najustesB3 = readRDS('data/b3_ajustes.rds')\n\nObtidos os dados, vamos filtrar o data.frame para os contratos de DI1. Note que o fechamento vem em preço, será necessário transformar em taxa. Deixei a conta explicita.\n\ndi1_data = ajustesB3 |&gt;\n  filter(commodity == 'DI1') |&gt;\n  mutate(date_vencimento = rb3::maturity2date(maturity_code),\n         date_vencimento_adj = bizdays::following(date_vencimento, 'Brazil/ANBIMA'), # Ajuste pois o vencimento pode cair em um feriado\n         du_ate_vcto = bizdays(refdate, date_vencimento_adj, 'Brazil/ANBIMA'), # Calculando o número de dias úteis até o vencimento do contrato\n         tx = ((100000/price)^(1/(du_ate_vcto/252))) -1) |&gt; \n  select(refdate, date_vencimento, date_vencimento_adj, du_ate_vcto, price, tx) |&gt;\n   filter(du_ate_vcto &gt; 0)\n\nglimpse(di1_data)\n\nRows: 150,498\nColumns: 6\n$ refdate             &lt;date&gt; 2006-01-02, 2006-01-02, 2006-01-02, 2006-01-02, 2…\n$ date_vencimento     &lt;date&gt; 2006-02-01, 2006-03-01, 2006-04-01, 2006-05-01, 2…\n$ date_vencimento_adj &lt;date&gt; 2006-02-01, 2006-03-01, 2006-04-03, 2006-05-02, 2…\n$ du_ate_vcto         &lt;dbl&gt; 22, 40, 63, 81, 124, 188, 249, 311, 373, 437, 499,…\n$ price               &lt;dbl&gt; 98587.33, 97464.78, 96079.17, 95023.89, 92627.65, …\n$ tx                  &lt;dbl&gt; 0.1769999, 0.1755996, 0.1734998, 0.1720998, 0.1684…\n\n\nNote que esta é uma estrutura dinâmica. O tempo passa, os contratos vencem. Para continuar o exercício, nós precisamos fixar as maturidades para trabalhar com taxas de 1,2,3 anos.\n\nultima_refdate_plot = di1_data |&gt;\nfilter(refdate == max(refdate) | refdate %in% c('2023-09-01', '2023-01-03', '2022-10-04', '2020-04-01')) |&gt;\nmutate(refdate = as.factor(refdate)) |&gt; \nggplot() + \n   geom_point(aes(x = date_vencimento, y = tx, colour = refdate)) +\n   geom_line(aes(x = date_vencimento, y = tx, colour = refdate)) +\n   theme_minimal() +\n   scale_y_continuous(labels = scales::percent) +\n   scale_colour_manual('', values = paleta_cores) +\n   labs(y = 'Taxa', x = 'Data de Vencimento do Contrato')\n\nggplotly(ultima_refdate_plot) |&gt;\n  add_title(title = 'Curva de Juros', subtitle_str = '% a.a.')\n\n\n\n\n\nPara isso, é necessário interpolar as curvas — não se assuste, você está apenas ligando os vértices para cada data de referência. Assim, será possível pegar du_ate_vcto fixos de cada refdate. O pacote fixedincome facilita o processo. Vamos criar um objeto SpotRateCurve para cada data de referência, adicionar um método de interpolação e salvar apenas os vértices de interesse.\nQuanto aos parâmetros: “discrete” é porque o método de capitalização utilizado é o discreto, “business/252” é porque nossa curva de juros é anualizada em 252 dias úteis e “Brazil/ANBIMA” para utilizar o calendário da ANBIMA para definir os dias úteis.\n\ndi1_data_l = di1_data |&gt; \n  arrange(refdate, date_vencimento_adj) |&gt;\n  split(di1_data$refdate) |&gt;\n  purrr::map(function(x){\n    curve = fixedincome::spotratecurve(x$tx, x$du_ate_vcto, refdate = unique(x$refdate),\n                               'discrete', 'business/252', 'Brazil/ANBIMA')\n    interpolation(curve) &lt;- fixedincome::interp_naturalspline()\n    curve\n  })\n\ncurvaDI1 = tibble::tibble(refdate = names(di1_data_l), curvadi1 = di1_data_l) \n\n# O legal do pacote é que ele tem umas funções de plot plugadas\n# p = curvaDI1 |&gt; filter(refdate == max(refdate)) |&gt;\n#     pull(curvadi1) %&gt;%\n#     pluck(1) |&gt;\n#     fixedincome::ggspotratecurveplot(use_interpolation = TRUE)\n# ggplotly(p)\n\n# Agora que temos um estrutura a termo interpolada para cada data de referência, conseguimos por exemplo, pegar a taxa de um ano para cada data de referência\ndus = c(\n        #21, 42, 63, 126, \n        252, 252*2, 252*3, 252*4, 252*5, 252*6, 252*7, 252*8, 252*9, 252*10\n        )\n\ndi1_constant_maturity = map_dfr(di1_data_l, \n          .f = function(x){\n            tx = x[[dus]] |&gt; as.numeric()\n            tibble(refdate = x@refdate,\n                   maturity = dus,\n                   tx = tx)\n          }\n)\nglimpse(di1_constant_maturity)\n\nRows: 43,150\nColumns: 3\n$ refdate  &lt;date&gt; 2006-01-02, 2006-01-02, 2006-01-02, 2006-01-02, 2006-01-02, …\n$ maturity &lt;dbl&gt; 252, 504, 756, 1008, 1260, 1512, 1764, 2016, 2268, 2520, 252,…\n$ tx       &lt;dbl&gt; 0.1637774, 0.1570996, 0.1539637, 0.1511227, 0.1486126, 0.1461…\n\n\nPara ilustrar o problema que acabamos de resolver, compare o gráfico abaixo com o primeiro gráfico que nós fixemos. Agora o gráfico não desloca mais, temos as taxas de 252 dias (1 ano), 504 dias (2 anos) e assim sucessivamente para cada ponto no tempo.\nE essa foi a evolução da nossa curva de juros de 2020 para cá.\n\np = di1_constant_maturity |&gt; \nfilter(refdate == max(refdate) | refdate %in% c('2023-09-01', '2023-01-03', '2022-01-03', '2021-01-04','2020-04-01', '2019-02-11')) |&gt;\nmutate(refdate = as.factor(refdate)) |&gt;\n    ggplot() +\n    geom_point(aes(x = maturity, y = tx, colour = refdate)) +\n   geom_line(aes(x = maturity, y = tx, colour = refdate)) +\n   theme_minimal() +\n   scale_x_continuous(breaks = dus) +\n   scale_y_continuous(labels = scales::percent) +\n   scale_colour_manual('', values = paleta_cores) +\n   labs(y = 'Taxa', x = 'DU')\n\nggplotly(p) |&gt;\n  add_title(title = 'Curva de Juros', subtitle_str = '% a.a.')\n\n\n\n\n\nE se a gente animar esse gráfico?\n\np = di1_constant_maturity |&gt;\n    group_by(refdate_month = month(refdate), refdate_year = year(refdate)) |&gt; # Pegando apenas o final de cada mês para não ficar muito pesado\n    filter(refdate == max(refdate)) |&gt;\n    ungroup() |&gt;\n    # mutate(refdate = as.factor(format(refdate, '%b-%y'))) |&gt;\n    ggplot() +\n      geom_point(aes(x = maturity, y = tx, frame = refdate), size = 2, colour = paleta_cores[1], show.legend = F)+\n      geom_line(aes(x = maturity, y = tx, frame = refdate), size = 1, colour = paleta_cores[1], show.legend = F) +\n      theme_minimal() +\n      scale_x_continuous(breaks = dus) +\n      scale_y_continuous(labels = scales::percent, n.breaks = 15) +\n      # scale_colour_manual('', values = paleta_cores) +\n      labs(y = 'Taxa', x = 'DU')\n\n# Você pode criar um plotly com um seletor de datas\nggplotly(p) |&gt;\nanimation_opts(1000, easing = 'elastic', redraw = FALSE) |&gt;\nanimation_button(x = 1, xanchor = 'right', y = 0, yanchor = 'bottom') |&gt;\nadd_title(title = 'Curva de Juros', subtitle_str = '% a.a.')\n# Ou se preferir, você pode criar um GIF\np +\n  theme_minimal(base_size = 16) +\n  transition_time(refdate) +\n  shadow_mark(alpha = 0.1) +\n  labs(subtitle = 'Ref. Date: {frame_time}')\n\n\n\n\n\n\n\n\n\n\n\n\nE mais gráficos.\n\n# Todos os vértices ao longo do tempo\np = di1_constant_maturity |&gt;\n    mutate(maturity = as.factor(maturity)) |&gt;\n    ggplot() +\n    geom_line(aes(x = refdate, y = tx, colour = maturity)) +\n   theme_minimal() +\n   scale_y_continuous(labels = scales::percent) +\n   scale_colour_manual('', values = paleta_cores) +\n   labs(y = 'Taxa', x = 'Data')\n\nggplotly(p) |&gt;\n  add_title(title = 'Curva de Juros', subtitle_str = '% a.a. por vértice')\n# Superfície com o Plotly\ndi1_constant_maturity_xts = di1_constant_maturity |&gt;\n  pivot_wider(id_cols = refdate, names_from = maturity, values_from = tx)\ndi1_constant_maturity_xts = xts(di1_constant_maturity_xts |&gt; select(-refdate), order.by = di1_constant_maturity_xts$refdate)\n\nplot_ly(z = ~di1_constant_maturity_xts, y = index(di1_constant_maturity_xts), x = names(di1_constant_maturity_xts),\n         colorbar = list(title = \"Taxa\")) %&gt;%\n  add_surface()  %&gt;%\n  layout(scene = list(\n           legend = list('Taxa'),\n           xaxis = list(title = \"DU\"),\n           yaxis = list(title = \"Data\"),\n           zaxis = list(title = \"Taxa\")\n         )) |&gt;\n  add_title(title = 'Curva de Juros', subtitle_str = '% a.a., por maturidade e data de referência')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2 Análise de Componentes Principais (PCA)\nAgora que temos tudo pronto, vamos seguir com a Análise de Componentes Principais. A ideia do PCA é que ele é capaz de para uma matriz de n x k, encontrar k-1 vetores independentes que contenham a maior parte da variabilidade encontrada nos vetores originais.\nComplicando um pouco, o algoritmo busca pelos autovalores e autovetores da matriz de covariância ou correlação das séries, retornando k-1 vetores linearmente independentes.\n\n# Vamos passar o df para wide e renomear os vértices para ficar mais claro\ndi1_constant_maturity_wide = di1_constant_maturity |&gt;\n  pivot_wider(id_cols = refdate, names_from = maturity, values_from = tx)\ncolnames(di1_constant_maturity_wide) &lt;-  c('refdate',paste0(as.numeric(\n  colnames(di1_constant_maturity_wide[-1])\n  )/252, 'Y'))\n\n# Conferindo se tem algum NA nos valores\nsummary(di1_constant_maturity_wide,digits = 4)\n\n    refdate                 1Y                2Y                3Y         \n Min.   :2006-01-02   Min.   :0.02195   Min.   :0.03230   Min.   :0.04211  \n 1st Qu.:2010-05-19   1st Qu.:0.07700   1st Qu.:0.08451   1st Qu.:0.09125  \n Median :2014-09-24   Median :0.10985   Median :0.11365   Median :0.11475  \n Mean   :2014-09-29   Mean   :0.10236   Mean   :0.10631   Mean   :0.10916  \n 3rd Qu.:2019-02-07   3rd Qu.:0.12637   3rd Qu.:0.12521   3rd Qu.:0.12497  \n Max.   :2023-11-17   Max.   :0.16400   Max.   :0.17442   Max.   :0.17832  \n       4Y                5Y                6Y                7Y         \n Min.   :0.04974   Min.   :0.05417   Min.   :0.05887   Min.   :0.06251  \n 1st Qu.:0.09533   1st Qu.:0.09790   1st Qu.:0.09982   1st Qu.:0.10100  \n Median :0.11621   Median :0.11674   Median :0.11732   Median :0.11778  \n Mean   :0.11118   Mean   :0.11238   Mean   :0.11337   Mean   :0.11417  \n 3rd Qu.:0.12567   3rd Qu.:0.12581   3rd Qu.:0.12586   3rd Qu.:0.12620  \n Max.   :0.18003   Max.   :0.18099   Max.   :0.18142   Max.   :0.18152  \n       8Y                9Y               10Y         \n Min.   :0.06454   Min.   :0.06574   Min.   :0.06658  \n 1st Qu.:0.10207   1st Qu.:0.10273   1st Qu.:0.10345  \n Median :0.11809   Median :0.11835   Median :0.11845  \n Mean   :0.11483   Mean   :0.11526   Mean   :0.11562  \n 3rd Qu.:0.12660   3rd Qu.:0.12668   3rd Qu.:0.12683  \n Max.   :0.18150   Max.   :0.18150   Max.   :0.18149  \n\n# Qual o desvio padrão de cada vértice da estrutura a termo?\napply(di1_constant_maturity_wide[,-1], 2, sd)\n\n        1Y         2Y         3Y         4Y         5Y         6Y         7Y \n0.03292263 0.02923815 0.02638453 0.02448931 0.02324738 0.02233972 0.02163290 \n        8Y         9Y        10Y \n0.02105460 0.02063642 0.02031346 \n\n\nAssim como foi visto no gráfico, aqui podemos ver que a correlação entre os vértices é bem alta. Logo, é bastante provável que com poucos componentes principais consigamos expressar a maior parte da variabilidade das séries.\nPara quem já viu um pouco de finanças isso não é surpresa. Dentre as várias teorias que explicam a estrutura a termo, a Teoria das Expectativas diz que as taxas de juros de X anos nada mais é do que uma combinação da taxa de 1 ano e das taxas de 1 ano esperadas. Isso surge de uma relação de não-arbitragem em que um investidor deve ser indiferente entre investir em um título de 2 anos e investir em um título de 1 ano e depois reinvestir por mais 1 ano.\n\np = di1_constant_maturity_wide |&gt;\n    filter(refdate &gt;= '2015-01-01') |&gt;\n    select(-refdate) |&gt;\n    corrr::correlate(quiet = T) |&gt;\n    corrr::rearrange() |&gt;\n    corrr::autoplot()\nggplotly(p) |&gt;\n  add_title(title = 'Matriz de Correlação', subtitle_str = 'entre os vértices da curva de juros')\n\n\n\n\n\nPara performar o PCA, temos a opção de tanto usar a matriz de covariância, como usar a matriz de correlação. Para essa aplicação especifica, vamos utilizar a matriz de correlação. Não queremos que o vértice de maior volatilidade domine sobre os demais. Esse problema fica bem mais evidente em outras aplicações em que as séries são bastante diferentes e com componentes idiossincráticos relevantes (e.g. taxas de câmbio).\n\n# Vamos utilizar o pacote factoextra para performar o PCA\n# Coloquei o processo numa função para extrairmos apenas o necessário\nget_pca_results &lt;- function(wide_data_frame){\n  \n  # PCA com normalização\n  pca &lt;- wide_data_frame |&gt;\n    select(-refdate) |&gt;\n    prcomp(scale. = T) # Scale = T utilizamos a matriz de correlação\n  \n  # Correlações\n  pca_corr = factoextra::get_pca(pca)$cor |&gt; as.data.frame.matrix() |&gt;\n    select(Dim.1:Dim.10) \n  \n  # Contribuição de cada PC \n  pca_cotrib = pca |&gt;\n    broom::tidy(matrix = 'd') |&gt;\n    filter(PC &lt;= 10) |&gt;\n    mutate(PC = as.character(PC)) \n\n  # Utilizando os loadings ou pesos para recuperar os componentes\n  PCs = as.matrix(wide_data_frame |&gt; select(-refdate)) %*% (pca$rotation*-1) |&gt;\n    as.data.frame.matrix() |&gt;\n    mutate(refdate = wide_data_frame$refdate) |&gt;\n    select(refdate, everything())\n  \n  list_results = list('prcomp.res'  = pca,\n       'correlation' = pca_corr,\n       'contrib' =  pca_cotrib,\n       'PCs' = PCs)\n  \n  return(list_results)\n}\ndi1_pca = get_pca_results(di1_constant_maturity_wide)\n\nVamos aos resultados. Primeiramente, sim, apenas 1 componente principal explica 97% da variabilidade em todos os 10 vértices que selecionamos da estrutura a termo. Os 3 primeiros componentes explicam praticamente 100%.\nMas o que tem em cada componente? Pois é, essa é a parte que mais me deixou curioso como um eterno aprendiz e iniciante em 999 coisas, embora para outras pessoas seja óbvio.\nVejamos as correlações dos componentes com as séries originais, bem como os loadings ou auto-vetores de cada componente. O loading nada mais é que a transformação linear que você aplica em cada série para obter o componente principal. Na prática, estamos construindo uma combinação linear de vértices. Cada combinação é linearmente independente da outra.\nO primeiro componente (PC1 ou Dim.1) tem alta correlação com todos os vértices e ela é bastante parecida em magnitude. De fato, como podemos ver no gráfico com os loadings, ele é uma combinação linear de pesos iguais de todos os vértices. Uma coisa que vou tentar mostrar posteriormente, é que, na prática, é como se estivessemos fazendo uma média de todos os vértices e extraindo um nível médio da curva naquela data de referência.\nO segundo componente (PC2) tem correlação negativa com os vértices curtos e positiva com os vértices mais longos. É como se estivéssemos pegando a parte longa da curva e subtraindo da parte curta. Dito de outra forma, o PC2 é um fator que traz a inclinação da curva de juros.\nPor fim, o PC3 ficou um pouco menos óbvio. O plot dos loadings tem quase um formato de U invertido, capturando um terceiro fator que é a curvatura da curva de juros.\nDe fato, essas ideias estão bem documentadas na literatura de finanças. Com esses 3 fatores, deveríamos ser capazes de reproduzir toda a estrutura a termo da taxa de juros.\n\n# Contribuição, Desvio Padrão por Componente principal\nreactable(di1_pca$contrib |&gt; filter(PC %in% as.character(c(1:5))),\n          defaultColDef = colDef(format = colFormat(digits = 4)),compact = T, pagination = F, fullWidth = F) |&gt;\n  reactablefmtr::add_title('Contribuição e Desvio Padrão por Componente Principal')\n\n\nContribuição e Desvio Padrão por Componente Principal\n\n\n\n# Correlação entre o Componente Principal e o Vértice da Estrutura a Termo\nreactable(di1_pca$correlation[,c(1:5)]*-1,\n          defaultColDef = colDef(format = colFormat(digits = 2), style = reactablefmtr::color_scales(di1_pca$correlation*-1)), compact = T, pagination = F, fullWidth = F) |&gt;\n  reactablefmtr::add_title('Correlação entre os PCs e os Vértice do DI')\n\n\nCorrelação entre os PCs e os Vértice do DI\n\n\n\n# Loadings \nf=paste0(1:10, 'Y')\ndf_loadings = (di1_pca$prcomp.res$rotation*-1) |&gt; as.data.frame()\ndf_loadings = df_loadings |&gt; mutate(vertice = rownames(df_loadings)) |&gt;\n  select(vertice, everything()) |&gt;\n  mutate(vertice = factor(vertice, levels = f))\n\np=df_loadings |&gt;\n  pivot_longer(cols = -1, names_to = 'PC', values_to = 'loading') |&gt;\n  filter(PC %in% c('PC1', 'PC2', 'PC3')) |&gt;\n  ggplot() +\n  geom_bar(stat = 'identity', aes(x = vertice, y = loading), fill = paleta_cores[6]) +\n  # geom_hline(aes(yintercept = 0), size = .5, linetype = 'dashed') +\n  theme_minimal() +\n  facet_wrap(~PC) +\n  labs(x = 'Vértice', y = '')\nggplotly(p) |&gt;\n  add_title(title = 'Loadings dos componentes principais', subtitle_str = '')\n\n\n\n\n\nAgora, nós vamos comparar: i) o primeiro componente principal (PC1) com uma métrica de nível da curva de juros; ii) o PC2 com uma medida de inclinação; e por fim, iii) o PC3 com uma métrica de curvatura.\nVamos definir a inclinação como sendo a difernça entre os juros de 10Y e os juros de 1Y. A curvatura será dada por 2*Média(4Y, 5Y, 6Y, 7Y)-(1Y+10Y). Já o nível é simplesmente a média de todos os vértices.\n\n#  Para isso vamos calcular os fatores nível, inclinação e curvatura com os dados originais\nfatores_curva = di1_constant_maturity_wide |&gt;\n  mutate(nivel = rowMeans(di1_constant_maturity_wide[,-1]),\n         inclinacao = `10Y`-`1Y`) |&gt;\n  rowwise() |&gt;\n  mutate(curvatura = 2*mean(c(`4Y`,`5Y`,`6Y`,`7Y`)) - (`1Y`+`10Y`)) |&gt;\n  ungroup() |&gt;\n  select(refdate, nivel, inclinacao, curvatura)\n\n# Merge com os componentes principais\nfatores_vs_pca = merge(di1_pca$PCs, fatores_curva, by = 'refdate')\n\nfatores_vs_pca_long = fatores_vs_pca |&gt;\n  pivot_longer(cols = -1)\n\nay &lt;- list(\n  #tickfont = list(color = \"red\"),\n  overlaying = \"y\",\n  side = \"right\"\n)\n\n# PC1 vs. Nível (Média das Vértices)\nplot_ly(data = fatores_vs_pca) %&gt;%\n  add_lines(x = ~refdate, y = ~nivel, name = \"Nível\",type = \"scatter\", mode = \"lines\",\n            line = list(color = paleta_cores[5])) %&gt;%\n  add_lines(x = ~refdate, y = ~PC1, name = \"PC1\", yaxis = \"y2\",type = \"scatter\", mode = \"lines\", line = list(color = paleta_cores[4])) %&gt;%\n  layout(\n    yaxis2 = ay,\n    xaxis = list(title=\"Date\", ticks=fatores_vs_pca$Date),\n    yaxis = list(title = '')\n  ) |&gt; add_title(title_str = 'PC1 vs Nível da Curva de Juros')\n# PC2 vs. Inclinação (10Y - 1Y)\nplot_ly(data = fatores_vs_pca) %&gt;%\n  add_lines(x = ~refdate, y = ~inclinacao, name = \"Inclinação\",type = \"scatter\", mode = \"lines\", line = list(color = paleta_cores[5])) %&gt;%\n  add_lines(x = ~refdate, y = ~PC2, name = \"PC2\", yaxis = \"y2\",type = \"scatter\", mode = \"lines\",line = list(color = paleta_cores[4])) %&gt;%\n  layout(\n    yaxis2 = ay,\n    xaxis = list(title=\"Date\", ticks=fatores_vs_pca$Date),\n    yaxis = list(title = '')\n  ) |&gt; add_title(title_str = 'PC2 vs Inclinação da Curva de Juros',\n                   subtitle = 'inclinação (eixo esq.), PC2 (eixo dir.)')\n# PC3 vs. Curvatura (Média(2Y,3Y,4Y,5Y,6Y) - (1Y+10Y))\nplot_ly(data = fatores_vs_pca) %&gt;%\n  add_lines(x = ~refdate, y = ~curvatura, name = \"Curvatura\",type = \"scatter\", mode = \"lines\",line = list(color = paleta_cores[5])) %&gt;%\n  add_lines(x = ~refdate, y = ~PC3, name = \"PC3\", yaxis = \"y2\",type = \"scatter\", mode = \"lines\",line = list(color = paleta_cores[4])) %&gt;%\n  layout(\n    yaxis2 = ay,\n    xaxis = list(title=\"Date\", ticks=fatores_vs_pca$Date),\n    yaxis = list(title = '')\n  ) |&gt; add_title(title_str = 'PC3 vs Curvatura da Curva de Juros',\n                 subtitle = 'curvatura (eixo esq.), PC3 (eixo dir.)')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComo pode ser visto, os resultados são bastante satisfatórios para os dois primeiros componentes. No caso da curvatura, o fit já não é tão bom, sobretudo no passado. É possível melhorar fazendo 2*(3Y) - (1Y+10Y) — replicando um pouco mais fielmente os loadings obtidos para o PC3, entretanto imagino que a ideia de “curvatura” perderia um pouco o sentido. Sendo assim, vamos manter o resultado que encontramos. Um possível motivo para o shape dos loadings do terceiro componente não ter sido o esperado diante da literatura seja as discrepâncias de liquidez entre os vértices.\nEnfim, essa é uma das intersecções mais interessantes que tive contato entre técnicas de machine learning e finanças.\nEnfim, obrigado se leu até aqui e se você encontrou algum erro ou alguma coisa muito estranha, pode me mandar mensagem ;)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "blog",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 20, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nNov 17, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  }
]